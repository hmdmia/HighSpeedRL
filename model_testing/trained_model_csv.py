import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
from matplotlib import rc, rcParams

def plot_shap_csv(filepath):
    """
    Plots SHAP excel results

    :param filename: CSV file of SHAP results
    :return: Scatter Plot
    """

    df = pd.read_csv(filepath)
    X = df[['time', 'altitude', 'velocity', 'FPA', 'aoa']]
    y = df[['aoa']].values.flatten()

    Z = X.values
    Z_scaled = Z

    X = pd.DataFrame(Z_scaled, columns=X.columns)

    time = []
    alt = []
    vel = []
    fpa = []
    aoa = []

    for row in range(len(X)):
        time.append(X.loc[row, 'time'])
        alt.append(X.loc[row, 'altitude'])
        vel.append(X.loc[row, 'velocity'])
        fpa.append(X.loc[row, 'FPA'])
        aoa.append(X.loc[row, 'aoa'])

    i = 1000
    alt[:] = [x / i for x in alt]

    plt.rcParams["font.weight"] = "bold"
    plt.rcParams["axes.labelweight"] = "bold"

    plt.scatter(time[0:44], aoa[0:44], facecolors='none', edgecolors='b')
    plt.plot(time[0:44], aoa[0:44], 'b')

    plt.xlabel('Time (s)')
    plt.ylabel('Angle of Attack (deg)')
    # plt.ylabel('Altitude (km)')

    plt.grid()
    plt.show()


def fail_detect(env, model, filename, fig = 'fig1'):
    """
    Run neural network until there is a failure observed or 1000 runs have completed

    :param env: RL environment used for training
    :param model: RL model generated by training
    :param filename: CSV file of SHAP results
    :param fig: save control/trajectory plot
    :return: CSV file
    """
    obs0 = []
    obs1 = []
    obs2 = []
    obs3 = []
    actions = []
    dones = []
    rewards = []

    success = []
    ctr = 0

    while 0 not in success:

        obs = env.reset()
        reward = 0.

        done = False
        obs0.append(obs[0])
        obs1.append(obs[1])
        obs2.append(obs[2])
        obs3.append(obs[3])
        dones.append(done)
        rewards.append(reward)

        ctr += 1
        while not done:
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, done, info = env.step(action)

            obs0.append(obs[0])
            obs1.append(obs[1])
            obs2.append(obs[2])
            obs3.append(obs[3])
            dones.append(done)
            rewards.append(reward)

            if done == True:
                if obs1[-1] <= 3000:
                    if obs3[-1] >= -0.25 * (3.14159 / 180):
                        success.append(1)
                    if ctr == 1000:
                        env.agent.plot_state_history(style='segmented')
                else:
                    env.agent.plot_control(style='segmented', save=fig)
                    success.append(0)
                    break

        if ctr > 1001:
            break

    d = {'Time': obs0, 'Altitude': obs1, 'Velocity': obs2, 'FPA': obs3, 'reward': rewards, 'done': dones}
    df = pd.DataFrame(data=d)
    Xy = df[df['done'] == False]
    Xy = Xy[['Time', 'Altitude', 'Velocity', 'FPA']]
    Xy['Action'] = actions
    Xy['Result'] = success

    Xy.to_csv( filename+'.csv')